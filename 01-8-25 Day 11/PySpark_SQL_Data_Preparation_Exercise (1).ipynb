{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Data Preparation"
      ],
      "metadata": {
        "id": "d-qy5Z67e-M4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5oVU84xseTjC",
        "outputId": "2f67f8ff-defe-4938-9d9d-949af1dbb679"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------+-------------+-----------+--------+---------+----------+\n",
            "|OrderID|CustomerName|Product      |Category   |Quantity|UnitPrice|OrderDate |\n",
            "+-------+------------+-------------+-----------+--------+---------+----------+\n",
            "|1      |Ravi        |Laptop       |Electronics|2       |50000    |2023-01-05|\n",
            "|2      |Sneha       |Jeans        |Clothing   |1       |2500     |2023-01-12|\n",
            "|3      |Kabir       |Desk         |Furniture  |1       |12000    |2023-02-01|\n",
            "|4      |Anita       |Chair        |Furniture  |3       |4500     |2023-02-18|\n",
            "|5      |Divya       |Smartphone   |Electronics|2       |30000    |2023-01-20|\n",
            "|6      |Manav       |Shirt        |Clothing   |4       |1500     |2023-03-12|\n",
            "|7      |Amit        |Tablet       |Electronics|1       |28000    |2023-03-25|\n",
            "|8      |Neha        |Lamp         |Furniture  |2       |3000     |2023-01-28|\n",
            "|9      |Farah       |Book - AI    |Books      |5       |900      |2023-04-01|\n",
            "|10     |Ravi        |Book - Python|Books      |3       |1200     |2023-04-10|\n",
            "|11     |Sneha       |T-shirt      |Clothing   |2       |700      |2023-05-05|\n",
            "|12     |Kabir       |Headphones   |Electronics|1       |4000     |2023-02-22|\n",
            "|13     |Divya       |Notebook     |Books      |2       |1500     |2023-05-20|\n",
            "|14     |Manav       |Table        |Furniture  |4       |3500     |2023-06-01|\n",
            "+-------+------------+-------------+-----------+--------+---------+----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession, Row\n",
        "\n",
        "spark = SparkSession.builder.appName(\"ProductOrdersSQL\").getOrCreate()\n",
        "\n",
        "data = [\n",
        "    Row(OrderID=1, CustomerName=\"Ravi\", Product=\"Laptop\", Category=\"Electronics\", Quantity=2, UnitPrice=50000, OrderDate=\"2023-01-05\"),\n",
        "    Row(OrderID=2, CustomerName=\"Sneha\", Product=\"Jeans\", Category=\"Clothing\", Quantity=1, UnitPrice=2500, OrderDate=\"2023-01-12\"),\n",
        "    Row(OrderID=3, CustomerName=\"Kabir\", Product=\"Desk\", Category=\"Furniture\", Quantity=1, UnitPrice=12000, OrderDate=\"2023-02-01\"),\n",
        "    Row(OrderID=4, CustomerName=\"Anita\", Product=\"Chair\", Category=\"Furniture\", Quantity=3, UnitPrice=4500, OrderDate=\"2023-02-18\"),\n",
        "    Row(OrderID=5, CustomerName=\"Divya\", Product=\"Smartphone\", Category=\"Electronics\", Quantity=2, UnitPrice=30000, OrderDate=\"2023-01-20\"),\n",
        "    Row(OrderID=6, CustomerName=\"Manav\", Product=\"Shirt\", Category=\"Clothing\", Quantity=4, UnitPrice=1500, OrderDate=\"2023-03-12\"),\n",
        "    Row(OrderID=7, CustomerName=\"Amit\", Product=\"Tablet\", Category=\"Electronics\", Quantity=1, UnitPrice=28000, OrderDate=\"2023-03-25\"),\n",
        "    Row(OrderID=8, CustomerName=\"Neha\", Product=\"Lamp\", Category=\"Furniture\", Quantity=2, UnitPrice=3000, OrderDate=\"2023-01-28\"),\n",
        "    Row(OrderID=9, CustomerName=\"Farah\", Product=\"Book - AI\", Category=\"Books\", Quantity=5, UnitPrice=900, OrderDate=\"2023-04-01\"),\n",
        "    Row(OrderID=10, CustomerName=\"Ravi\", Product=\"Book - Python\", Category=\"Books\", Quantity=3, UnitPrice=1200, OrderDate=\"2023-04-10\"),\n",
        "    Row(OrderID=11, CustomerName=\"Sneha\", Product=\"T-shirt\", Category=\"Clothing\", Quantity=2, UnitPrice=700, OrderDate=\"2023-05-05\"),\n",
        "    Row(OrderID=12, CustomerName=\"Kabir\", Product=\"Headphones\", Category=\"Electronics\", Quantity=1, UnitPrice=4000, OrderDate=\"2023-02-22\"),\n",
        "    Row(OrderID=13, CustomerName=\"Divya\", Product=\"Notebook\", Category=\"Books\", Quantity=2, UnitPrice=1500, OrderDate=\"2023-05-20\"),\n",
        "    Row(OrderID=14, CustomerName=\"Manav\", Product=\"Table\", Category=\"Furniture\", Quantity=4, UnitPrice=3500, OrderDate=\"2023-06-01\")\n",
        "]\n",
        "\n",
        "df = spark.createDataFrame(data)\n",
        "df.createOrReplaceTempView(\"orders_local\")\n",
        "df.createOrReplaceGlobalTempView(\"orders_global\")\n",
        "df.show(truncate=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part A: Local View – orders_local"
      ],
      "metadata": {
        "id": "GmXC_oF_f9k7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. List all orders placed for \"Electronics\" with a Quantity of 2 or more."
      ],
      "metadata": {
        "id": "mWLFD1S6gFtV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"select * from orders_local where category = 'Electronics' AND Quantity >=2\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pf-4Ra1egE9w",
        "outputId": "974281bc-f9af-4545-eabb-c38f8139f463"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------+----------+-----------+--------+---------+----------+\n",
            "|OrderID|CustomerName|   Product|   Category|Quantity|UnitPrice| OrderDate|\n",
            "+-------+------------+----------+-----------+--------+---------+----------+\n",
            "|      1|        Ravi|    Laptop|Electronics|       2|    50000|2023-01-05|\n",
            "|      5|       Divya|Smartphone|Electronics|       2|    30000|2023-01-20|\n",
            "+-------+------------+----------+-----------+--------+---------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Calculate TotalAmount (Quantity × UnitPrice) for each order."
      ],
      "metadata": {
        "id": "KtBuAYEygH5P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"select * ,(Quantity * UnitPrice) as TotalAmount from orders_local\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHhOVThBhEB7",
        "outputId": "0dab5525-5891-4eae-8cdf-5fc567d0127a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------+-------------+-----------+--------+---------+----------+-----------+\n",
            "|OrderID|CustomerName|      Product|   Category|Quantity|UnitPrice| OrderDate|TotalAmount|\n",
            "+-------+------------+-------------+-----------+--------+---------+----------+-----------+\n",
            "|      1|        Ravi|       Laptop|Electronics|       2|    50000|2023-01-05|     100000|\n",
            "|      2|       Sneha|        Jeans|   Clothing|       1|     2500|2023-01-12|       2500|\n",
            "|      3|       Kabir|         Desk|  Furniture|       1|    12000|2023-02-01|      12000|\n",
            "|      4|       Anita|        Chair|  Furniture|       3|     4500|2023-02-18|      13500|\n",
            "|      5|       Divya|   Smartphone|Electronics|       2|    30000|2023-01-20|      60000|\n",
            "|      6|       Manav|        Shirt|   Clothing|       4|     1500|2023-03-12|       6000|\n",
            "|      7|        Amit|       Tablet|Electronics|       1|    28000|2023-03-25|      28000|\n",
            "|      8|        Neha|         Lamp|  Furniture|       2|     3000|2023-01-28|       6000|\n",
            "|      9|       Farah|    Book - AI|      Books|       5|      900|2023-04-01|       4500|\n",
            "|     10|        Ravi|Book - Python|      Books|       3|     1200|2023-04-10|       3600|\n",
            "|     11|       Sneha|      T-shirt|   Clothing|       2|      700|2023-05-05|       1400|\n",
            "|     12|       Kabir|   Headphones|Electronics|       1|     4000|2023-02-22|       4000|\n",
            "|     13|       Divya|     Notebook|      Books|       2|     1500|2023-05-20|       3000|\n",
            "|     14|       Manav|        Table|  Furniture|       4|     3500|2023-06-01|      14000|\n",
            "+-------+------------+-------------+-----------+--------+---------+----------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Show the total number of orders per Category ."
      ],
      "metadata": {
        "id": "J7Mv2yYvgJx5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"select Category, Count(*) as TotalOrders from orders_local group by Category\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMMnlcPmhpWn",
        "outputId": "75620bce-753c-433f-e59e-3ec0b7ddf6f0"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+\n",
            "|   Category|TotalOrders|\n",
            "+-----------+-----------+\n",
            "|Electronics|          4|\n",
            "|   Clothing|          3|\n",
            "|  Furniture|          4|\n",
            "|      Books|          3|\n",
            "+-----------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. List orders placed in \"January 2023\" only."
      ],
      "metadata": {
        "id": "jK6HT0YKgMXn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"select * from orders_local where OrderDate BETWEEN '2023-01-01' AND '2023-01-31'\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBOFp7hIifGY",
        "outputId": "c3100f51-c8d4-4267-d7c7-a9a4febe9831"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------+----------+-----------+--------+---------+----------+\n",
            "|OrderID|CustomerName|   Product|   Category|Quantity|UnitPrice| OrderDate|\n",
            "+-------+------------+----------+-----------+--------+---------+----------+\n",
            "|      1|        Ravi|    Laptop|Electronics|       2|    50000|2023-01-05|\n",
            "|      2|       Sneha|     Jeans|   Clothing|       1|     2500|2023-01-12|\n",
            "|      5|       Divya|Smartphone|Electronics|       2|    30000|2023-01-20|\n",
            "|      8|        Neha|      Lamp|  Furniture|       2|     3000|2023-01-28|\n",
            "+-------+------------+----------+-----------+--------+---------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Show the average UnitPrice per category."
      ],
      "metadata": {
        "id": "d-RaRwaUgOTR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"select Category, Avg(UnitPrice) as Avg_UnitPrice from orders_local group by Category\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KeJqSIa9jedO",
        "outputId": "088c726d-cc89-4f6a-c5f3-a08c971c19e3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+------------------+\n",
            "|   Category|     Avg_UnitPrice|\n",
            "+-----------+------------------+\n",
            "|Electronics|           28000.0|\n",
            "|   Clothing|1566.6666666666667|\n",
            "|  Furniture|            5750.0|\n",
            "|      Books|            1200.0|\n",
            "+-----------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Find the order with the highest total amount."
      ],
      "metadata": {
        "id": "agc3L8ZkgPKV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"select *, (Quantity * UnitPrice) as TotalAmount from orders_local order by TotalAmount DESC LIMIT 1\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LpkoxfkjyAV",
        "outputId": "3e145397-6514-4c7e-9f75-7639ed3a92cf"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------+-------+-----------+--------+---------+----------+-----------+\n",
            "|OrderID|CustomerName|Product|   Category|Quantity|UnitPrice| OrderDate|TotalAmount|\n",
            "+-------+------------+-------+-----------+--------+---------+----------+-----------+\n",
            "|      1|        Ravi| Laptop|Electronics|       2|    50000|2023-01-05|     100000|\n",
            "+-------+------------+-------+-----------+--------+---------+----------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Drop the local view and try querying it again."
      ],
      "metadata": {
        "id": "u7HbN66ggQ3h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.catalog.dropTempView(\"orders_local\")\n",
        "spark.sql(\"SELECT * FROM orders_local\").show()  # This will now show error"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "VFfWf2cIgTwR",
        "outputId": "c56d1ee1-f537-48b6-fee8-f6c53b81c8ec"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AnalysisException",
          "evalue": "[TABLE_OR_VIEW_NOT_FOUND] The table or view `orders_local` cannot be found. Verify the spelling and correctness of the schema and catalog.\nIf you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\nTo tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 1 pos 14;\n'Project [*]\n+- 'UnresolvedRelation [orders_local], [], false\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3019090737.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatalog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropTempView\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"orders_local\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SELECT * FROM orders_local\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# This will now show error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyspark/sql/session.py\u001b[0m in \u001b[0;36msql\u001b[0;34m(self, sqlQuery, args, **kwargs)\u001b[0m\n\u001b[1;32m   1629\u001b[0m                     \u001b[0;34m[\u001b[0m\u001b[0m_to_java_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1630\u001b[0m                 )\n\u001b[0;32m-> 1631\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqlQuery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlitArgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1632\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAnalysisException\u001b[0m: [TABLE_OR_VIEW_NOT_FOUND] The table or view `orders_local` cannot be found. Verify the spelling and correctness of the schema and catalog.\nIf you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\nTo tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 1 pos 14;\n'Project [*]\n+- 'UnresolvedRelation [orders_local], [], false\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part B: Global View – orders_global"
      ],
      "metadata": {
        "id": "83naXKHxgUG9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Display all \"Furniture\" orders with TotalAmount above\n",
        "10,000."
      ],
      "metadata": {
        "id": "5OyEN_lpgVUb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"select *, (Quantity * UnitPrice) as TotalAmount from global_temp.orders_global where Category = 'Furniture' AND (Quantity * UnitPrice)  > 10000\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VR-R3etYgYH6",
        "outputId": "9b1e7fef-b46e-4972-dfd8-8dabf04896c2"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------+-------+---------+--------+---------+----------+-----------+\n",
            "|OrderID|CustomerName|Product| Category|Quantity|UnitPrice| OrderDate|TotalAmount|\n",
            "+-------+------------+-------+---------+--------+---------+----------+-----------+\n",
            "|      3|       Kabir|   Desk|Furniture|       1|    12000|2023-02-01|      12000|\n",
            "|      4|       Anita|  Chair|Furniture|       3|     4500|2023-02-18|      13500|\n",
            "|     14|       Manav|  Table|Furniture|       4|     3500|2023-06-01|      14000|\n",
            "+-------+------------+-------+---------+--------+---------+----------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Create a column called DiscountFlag :\n",
        "Mark \"Yes\" if Quantity > 3\n",
        "Otherwise \"No\""
      ],
      "metadata": {
        "id": "UkwkUx7ogYdz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"\"\"select *, CASE when Quantity > 3 THEN 'Yes'\n",
        "ELSE 'No' END AS DiscountFlag from global_temp.orders_global\"\"\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hK73ttFUmNVg",
        "outputId": "81898afe-022a-455d-a8a2-ba890a5c577d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------+-------------+-----------+--------+---------+----------+------------+\n",
            "|OrderID|CustomerName|      Product|   Category|Quantity|UnitPrice| OrderDate|DiscountFlag|\n",
            "+-------+------------+-------------+-----------+--------+---------+----------+------------+\n",
            "|      1|        Ravi|       Laptop|Electronics|       2|    50000|2023-01-05|          No|\n",
            "|      2|       Sneha|        Jeans|   Clothing|       1|     2500|2023-01-12|          No|\n",
            "|      3|       Kabir|         Desk|  Furniture|       1|    12000|2023-02-01|          No|\n",
            "|      4|       Anita|        Chair|  Furniture|       3|     4500|2023-02-18|          No|\n",
            "|      5|       Divya|   Smartphone|Electronics|       2|    30000|2023-01-20|          No|\n",
            "|      6|       Manav|        Shirt|   Clothing|       4|     1500|2023-03-12|         Yes|\n",
            "|      7|        Amit|       Tablet|Electronics|       1|    28000|2023-03-25|          No|\n",
            "|      8|        Neha|         Lamp|  Furniture|       2|     3000|2023-01-28|          No|\n",
            "|      9|       Farah|    Book - AI|      Books|       5|      900|2023-04-01|         Yes|\n",
            "|     10|        Ravi|Book - Python|      Books|       3|     1200|2023-04-10|          No|\n",
            "|     11|       Sneha|      T-shirt|   Clothing|       2|      700|2023-05-05|          No|\n",
            "|     12|       Kabir|   Headphones|Electronics|       1|     4000|2023-02-22|          No|\n",
            "|     13|       Divya|     Notebook|      Books|       2|     1500|2023-05-20|          No|\n",
            "|     14|       Manav|        Table|  Furniture|       4|     3500|2023-06-01|         Yes|\n",
            "+-------+------------+-------------+-----------+--------+---------+----------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. List customers who ordered more than 1 product type (Hint: use GROUP BY and\n",
        "HAVING)."
      ],
      "metadata": {
        "id": "Oa2aMxyFgaAe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"\"\"select CustomerName from global_temp.orders_global\n",
        "GROUP BY CustomerName\n",
        "HAVING COUNT(DISTINCT Category) > 1\n",
        "\"\"\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmZprjm9gay-",
        "outputId": "8b63519f-ae74-422f-9697-f6c2a56b756c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+\n",
            "|CustomerName|\n",
            "+------------+\n",
            "|       Divya|\n",
            "|        Ravi|\n",
            "|       Kabir|\n",
            "|       Manav|\n",
            "+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Count number of orders per month across the dataset."
      ],
      "metadata": {
        "id": "5DtBbPGVgbPE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"\"\"select substring(OrderDate, 1, 7) AS Month, COUNT(*) as OrderCount\n",
        "from global_temp.orders_global\n",
        "GROUP BY Month\n",
        "ORDER BY Month\n",
        "\"\"\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xq2ofL7Ngck9",
        "outputId": "f8baea99-2533-4d6c-f647-d00255096549"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+\n",
            "|  Month|OrderCount|\n",
            "+-------+----------+\n",
            "|2023-01|         4|\n",
            "|2023-02|         3|\n",
            "|2023-03|         2|\n",
            "|2023-04|         2|\n",
            "|2023-05|         2|\n",
            "|2023-06|         1|\n",
            "+-------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Rank all products by total quantity sold across all orders using a window\n",
        "function."
      ],
      "metadata": {
        "id": "1lp2vMHkgc5m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, sum as Fsum\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import rank\n",
        "\n",
        "prod_qty = df.groupBy(\"Product\").agg(Fsum(\"Quantity\").alias(\"TotalQuantity\"))\n",
        "\n",
        "windowSpec = Window.orderBy(col(\"TotalQuantity\").desc())\n",
        "ranked = prod_qty.withColumn(\"Rank\", rank().over(windowSpec))\n",
        "ranked.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oW2zHt6Agfhw",
        "outputId": "c51945d0-797f-4a84-87c1-ca54714ed126"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+-------------+----+\n",
            "|      Product|TotalQuantity|Rank|\n",
            "+-------------+-------------+----+\n",
            "|    Book - AI|            5|   1|\n",
            "|        Shirt|            4|   2|\n",
            "|        Table|            4|   2|\n",
            "|        Chair|            3|   4|\n",
            "|Book - Python|            3|   4|\n",
            "|       Laptop|            2|   6|\n",
            "|   Smartphone|            2|   6|\n",
            "|      T-shirt|            2|   6|\n",
            "|         Lamp|            2|   6|\n",
            "|     Notebook|            2|   6|\n",
            "|         Desk|            1|  11|\n",
            "|       Tablet|            1|  11|\n",
            "|        Jeans|            1|  11|\n",
            "|   Headphones|            1|  11|\n",
            "+-------------+-------------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Run a query using a new SparkSession and the global view."
      ],
      "metadata": {
        "id": "-16rpg52gf-q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_Spark = SparkSession.builder.appName(\"NewSession\").getOrCreate()\n",
        "new_Spark.sql(\"select * from global_temp.orders_global\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Gfu3x0mgiha",
        "outputId": "7d43b72b-1f76-4ad7-b346-30b4415dca3a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------+-------------+-----------+--------+---------+----------+\n",
            "|OrderID|CustomerName|      Product|   Category|Quantity|UnitPrice| OrderDate|\n",
            "+-------+------------+-------------+-----------+--------+---------+----------+\n",
            "|      1|        Ravi|       Laptop|Electronics|       2|    50000|2023-01-05|\n",
            "|      2|       Sneha|        Jeans|   Clothing|       1|     2500|2023-01-12|\n",
            "|      3|       Kabir|         Desk|  Furniture|       1|    12000|2023-02-01|\n",
            "|      4|       Anita|        Chair|  Furniture|       3|     4500|2023-02-18|\n",
            "|      5|       Divya|   Smartphone|Electronics|       2|    30000|2023-01-20|\n",
            "|      6|       Manav|        Shirt|   Clothing|       4|     1500|2023-03-12|\n",
            "|      7|        Amit|       Tablet|Electronics|       1|    28000|2023-03-25|\n",
            "|      8|        Neha|         Lamp|  Furniture|       2|     3000|2023-01-28|\n",
            "|      9|       Farah|    Book - AI|      Books|       5|      900|2023-04-01|\n",
            "|     10|        Ravi|Book - Python|      Books|       3|     1200|2023-04-10|\n",
            "|     11|       Sneha|      T-shirt|   Clothing|       2|      700|2023-05-05|\n",
            "|     12|       Kabir|   Headphones|Electronics|       1|     4000|2023-02-22|\n",
            "|     13|       Divya|     Notebook|      Books|       2|     1500|2023-05-20|\n",
            "|     14|       Manav|        Table|  Furniture|       4|     3500|2023-06-01|\n",
            "+-------+------------+-------------+-----------+--------+---------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bonus Challenges"
      ],
      "metadata": {
        "id": "mqDNkHd6gi3c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Save a filtered subset (only \"Books\" category) as a new global temp view."
      ],
      "metadata": {
        "id": "D5hvL2ofgkld"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "books_df = df.filter(col(\"Category\") == \"Books\")\n",
        "books_df.createOrReplaceGlobalTempView(\"books_only\")\n"
      ],
      "metadata": {
        "id": "M18g4He5gkI0"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Find the most purchased product per category."
      ],
      "metadata": {
        "id": "0q_6wEg-gm6u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import row_number\n",
        "\n",
        "prod_sum = df.groupBy(\"Category\", \"Product\").agg(Fsum(\"Quantity\").alias(\"Qty\"))\n",
        "window = Window.partitionBy(\"Category\").orderBy(col(\"Qty\").desc())\n",
        "top_per_cat = prod_sum.withColumn(\"rn\", row_number().over(window)).filter(\"rn = 1\")\n",
        "top_per_cat.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wIvz1I4lgoZa",
        "outputId": "7b6b7e79-1ece-4c01-82d1-3cb416f90a5c"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+---------+---+---+\n",
            "|   Category|  Product|Qty| rn|\n",
            "+-----------+---------+---+---+\n",
            "|      Books|Book - AI|  5|  1|\n",
            "|   Clothing|    Shirt|  4|  1|\n",
            "|Electronics|   Laptop|  2|  1|\n",
            "|  Furniture|    Table|  4|  1|\n",
            "+-----------+---------+---+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Create a view that excludes all \"Clothing\" orders and call it\n",
        "\"filtered_orders\" ."
      ],
      "metadata": {
        "id": "uBhz9F8Bgoqr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.filter(col(\"Category\") != \"Clothing\").createOrReplaceTempView(\"filtered_orders\")\n",
        "spark.sql(\"SELECT * FROM filtered_orders\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ki9QiYPFgqai",
        "outputId": "c2ac8a91-7cc5-4b17-9264-6c8374c124e3"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------+-------------+-----------+--------+---------+----------+\n",
            "|OrderID|CustomerName|      Product|   Category|Quantity|UnitPrice| OrderDate|\n",
            "+-------+------------+-------------+-----------+--------+---------+----------+\n",
            "|      1|        Ravi|       Laptop|Electronics|       2|    50000|2023-01-05|\n",
            "|      3|       Kabir|         Desk|  Furniture|       1|    12000|2023-02-01|\n",
            "|      4|       Anita|        Chair|  Furniture|       3|     4500|2023-02-18|\n",
            "|      5|       Divya|   Smartphone|Electronics|       2|    30000|2023-01-20|\n",
            "|      7|        Amit|       Tablet|Electronics|       1|    28000|2023-03-25|\n",
            "|      8|        Neha|         Lamp|  Furniture|       2|     3000|2023-01-28|\n",
            "|      9|       Farah|    Book - AI|      Books|       5|      900|2023-04-01|\n",
            "|     10|        Ravi|Book - Python|      Books|       3|     1200|2023-04-10|\n",
            "|     12|       Kabir|   Headphones|Electronics|       1|     4000|2023-02-22|\n",
            "|     13|       Divya|     Notebook|      Books|       2|     1500|2023-05-20|\n",
            "|     14|       Manav|        Table|  Furniture|       4|     3500|2023-06-01|\n",
            "+-------+------------+-------------+-----------+--------+---------+----------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}